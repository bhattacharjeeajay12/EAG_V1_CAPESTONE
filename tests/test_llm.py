# test_llm.py
from core.llm_client import LLMClient

# Test if LLM client works
llm = LLMClient()
test_prompt = "Who came first chicken or egg? Answer in one word."

try:
    response = llm.generate(test_prompt)
    print(f"âœ… LLM Response: {response}")
except Exception as e:
    print(f"âŒ LLM Error: {str(e)}")
    print("ğŸ’¡ This explains why decision engine defaults to 'clarify'")